{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "552d3f7c-15c6-4b62-a394-750ecae7c714",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ICC Points Table\n",
    "### Problem:\n",
    "Generate an output table which gives a report of Number of Matches played by each country, Number of Wins and Number of losses.\n",
    "\n",
    "Final Ouput should look like:\n",
    "| Team Name | Matches_Played | no_of_wins | no_of_losses |\n",
    "|-----|------|------------------|----------------|\n",
    "| India | 2 | 2 | 0 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c86a188-cc51-473a-af29-845b76f18c5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Switch to my Catalog\n",
    "USE CATALOG workspace;\n",
    "\n",
    "-- Create schema if not exists\n",
    "CREATE SCHEMA IF NOT EXISTS sql_pyspark_practice;\n",
    "\n",
    "-- Use this schema\n",
    "USE sql_pyspark_practice;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52368263-97dd-49d8-99e0-9a48378e459d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create or replace table icc_world_cup\n",
    "(\n",
    "Team_1 Varchar(20),\n",
    "Team_2 Varchar(20),\n",
    "Winner Varchar(20)\n",
    ");\n",
    "\n",
    "INSERT INTO icc_world_cup values('India','SL','India');\n",
    "INSERT INTO icc_world_cup values('SL','Aus','Aus');\n",
    "INSERT INTO icc_world_cup values('SA','Eng','Eng');\n",
    "INSERT INTO icc_world_cup values('Eng','NZ','NZ');\n",
    "INSERT INTO icc_world_cup values('Aus','India','India');\n",
    "\n",
    "select * from icc_world_cup;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1fda806-8790-49f0-9f92-4914860d9fe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SQL Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8e12a46-9ec6-44f1-9bbc-d729eb6b4ac5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "select Team_Name, count(1) as no_of_matches_played, sum(win_flag) as no_of_wins, (count(1) - sum(win_flag)) as no_of_losses  \n",
    "from (\n",
    "  select team_1 as Team_Name, case when team_1=winner then 1 else 0 end as win_flag\n",
    "  from icc_world_cup\n",
    "  union all\n",
    "  select team_2 as Team_Name, case when team_2=winner then 1 else 0 end as win_flag\n",
    "  from icc_world_cup \n",
    ") A\n",
    "group by Team_Name\n",
    "order by no_of_wins desc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeb8f393-7148-46ca-9bdd-6497c2460a54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PySpark Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd011df1-0f6e-48e4-933b-75332df75d34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Read Source table\n",
    "df = spark.table(\"icc_world_cup\")\n",
    "\n",
    "# Combine 2 columns \n",
    "df_union = (\n",
    "            df.select(\n",
    "                F.col(\"Team_1\").alias(\"Team_Name\"),\n",
    "                F.when(F.col(\"Team_1\") == F.col(\"Winner\"),1).otherwise(0).alias(\"win_flag\")\n",
    "                )\n",
    "            .unionAll(\n",
    "                df.select(\n",
    "                    F.col(\"Team_2\").alias(\"Team_Name\"),\n",
    "                    F.when(F.col(\"Team_2\") == F.col(\"Winner\"),1).otherwise(0).alias(\"win_flag\"))\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Group, Aggregate, Derive and Order Pipeline\n",
    "df_final = (\n",
    "    df_union\n",
    "    .groupBy(\"Team_Name\")\n",
    "    .agg(\n",
    "        F.count(\"Team_Name\").alias(\"no_of_matches_played\"),\n",
    "        F.sum(\"win_flag\").alias(\"no_of_wins\")\n",
    "        )\n",
    "    .withColumn(\n",
    "        \"no_of_losses\",\n",
    "        F.col(\"no_of_matches_played\") - F.col(\"no_of_wins\")\n",
    "        )\n",
    "    .orderBy(\"no_of_wins\", ascending=False)\n",
    "    )\n",
    "\n",
    "display(df_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95136d33-2375-47da-b152-5f9458f2de6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Notes\n",
    "1. **Read table**\n",
    "   `df = spark.table(\"icc_world_cup\")`\n",
    "   → Load SQL table into PySpark DataFrame.\n",
    "\n",
    "2. **Create 2 DataFrames** (`df_team1`, `df_team2`)\n",
    "   → Select team names and use `F.when(...).otherwise(...)` to create `win_flag`.\n",
    "\n",
    "3. **Union both**\n",
    "   `df_union = df_team1.union(df_team2)`\n",
    "   → Combine all teams (Team_1 + Team_2).\n",
    "\n",
    "4. **Group & Aggregate**\n",
    "   → `groupBy(\"Team_Name\")`, then\n",
    "   `count()` → matches played\n",
    "   `sum()` → wins.\n",
    "\n",
    "5. **Add derived column**\n",
    "   → `no_of_losses = no_of_matches_played - no_of_wins`.\n",
    "\n",
    "6. **Order results**\n",
    "   → Sort by `no_of_wins` (descending).\n",
    "\n",
    "7. **Display final output**\n",
    "   → `display(df_final)` in Databricks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3b28ab2-d30c-4d90-b381-3170d71efd90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Learnings\n",
    "### 10th Nov 2025\n",
    "- Learnt about Git integration in Databricks.\n",
    "- Learnt about Union and Union all Use cases in sql\n",
    "- Learnt about PySpark syntax\n",
    "- Usage of Functions, Select, Union All, Aggregate functions, Groupby & orderBy in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eb4b3e9e-b548-4681-91ee-46392b1c09ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Prob_01",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
