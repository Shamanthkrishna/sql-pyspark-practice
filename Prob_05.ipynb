{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18a55155-60a4-46bc-af89-20f8c907c312",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Pivot - Unpivot\n",
    "The problem is to handle employee compensation data stored in a long format where each component appears as a separate row, and to reshape it into a wide pivoted format with components as columns, while also enabling the reverse transformation by unpivoting the wide table back into the original long format for flexible analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e3b46ca-13c6-4d05-825e-3dfddea8c948",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Switch to my Catalog\n",
    "USE CATALOG workspace;\n",
    "\n",
    "-- Create schema if not exists\n",
    "CREATE SCHEMA IF NOT EXISTS sql_pyspark_practice;\n",
    "\n",
    "-- Use this schema\n",
    "USE sql_pyspark_practice;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42092c63-f0fc-4652-800f-ced794f049c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table emp_compensation (\n",
    "emp_id int,\n",
    "salary_component_type varchar(20),\n",
    "val int\n",
    ");\n",
    "\n",
    "insert into emp_compensation\n",
    "values (1,'salary',10000),(1,'bonus',5000),(1,'hike_percent',10)\n",
    ", (2,'salary',15000),(2,'bonus',7000),(2,'hike_percent',8)\n",
    ", (3,'salary',12000),(3,'bonus',6000),(3,'hike_percent',7);\n",
    "\n",
    "select * from emp_compensation;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9be8d719-7371-4f18-82e9-df27baf1c161",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f9e0cd0-4c80-4a3f-ab38-3defb3b7a42a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SQL Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2a4b5d4-0f8d-4aa0-9b99-7c8f63ed25ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table emp_compensation_pivot as \n",
    "select emp_id,\n",
    "        sum(case when salary_component_type = 'salary' then val end) as salary,\n",
    "        sum(case when salary_component_type = 'bonus' then val end) as bonus,\n",
    "        sum(case when salary_component_type = 'hike_percent' then val end) as hike_percent\n",
    "from emp_compensation\n",
    "group by emp_id;\n",
    "\n",
    "select * from emp_compensation_pivot;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fb5d61d-2442-45ef-bfae-5b2684c77c39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PySpark Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "420c9ee9-ce83-478e-84db-e34a2c03705d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = spark.table(\"emp_compensation\")\n",
    "display(df)\n",
    "\n",
    "\n",
    "df_pivot = df.groupBy(\"emp_id\").pivot(\"salary_component_type\").agg(sum(\"val\"))\n",
    "\n",
    "df_final = df_pivot.select(\n",
    "    col(\"emp_id\"),\n",
    "    col(\"salary\"),\n",
    "    col(\"bonus\"),\n",
    "    col(\"hike_percent\")\n",
    ")\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd1f4bfc-f264-4729-afc2-2734656e140f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Unpivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03de8f0a-3bdf-41a5-9b2c-2b9359f5471e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### SQL Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bced3b6a-c3a6-47d5-b8ef-0e3efc97e3b5",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763104340685}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "select emp_id, 'salary' as salaray_component_type, salary as val from emp_compensation_pivot\n",
    "union all\n",
    "select emp_id, 'bonus' as salaray_component_type, bonus as val from emp_compensation_pivot\n",
    "union all\n",
    "select emp_id, 'hike_percent' as salaray_component_type, hike_percent as val from emp_compensation_pivot;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1935d748-7c70-41dc-8c61-5f409392eb1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### PySpark Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "648162ed-0fc0-4034-8ea5-962981829642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_unpivot = df_final.selectExpr(\"emp_id\", \"stack(3, 'salary', salary, 'bonus', bonus, 'hike_percent', hike_percent) as (salary_component_type, val)\")\n",
    "display(df_unpivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d904bfe4-84bc-45c6-9f9a-12af48a42d45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Learnings\n",
    "\n",
    "### âœ… **Outcome**\n",
    "\n",
    "* Successfully converted **tall/long data â†’ wide format (pivot)** and then **wide â†’ long format (unpivot)** using both **SQL** and **PySpark**.\n",
    "* Got equivalent results in SQL tables and PySpark DataFrames.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ **What I Learnt**\n",
    "\n",
    "* How to **pivot** data in SQL using CASE + GROUP BY.\n",
    "* How to **pivot** in PySpark using `groupBy().pivot().agg()`.\n",
    "* How to **unpivot** in SQL using `UNION ALL`.\n",
    "* How to **unpivot** in PySpark using `stack()`.\n",
    "* Understanding of data reshaping between **row-based** and **column-based** formats.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸªœ **Steps Done**\n",
    "\n",
    "1. Created base table `emp_compensation` (long format).\n",
    "2. Built a pivoted table using:\n",
    "\n",
    "   * SQL CASE statements\n",
    "   * PySpark pivot function\n",
    "3. Built an unpivoted version using:\n",
    "\n",
    "   * SQL `UNION ALL`\n",
    "   * PySpark `stack()` function\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“˜ **Main Topics Covered (SQL + PySpark)**\n",
    "\n",
    "* **SQL**\n",
    "\n",
    "  * `GROUP BY`\n",
    "  * Conditional aggregation (`CASE WHEN`)\n",
    "  * `UNION ALL`\n",
    "  * Table creation\n",
    "  * PIVOT/UNPIVOT logic manually\n",
    "\n",
    "* **PySpark**\n",
    "\n",
    "  * DataFrame creation using `spark.table()`\n",
    "  * `groupBy()`\n",
    "  * `pivot()`\n",
    "  * `agg(sum())`\n",
    "  * `selectExpr()`\n",
    "  * `stack()` for unpivot\n",
    "  * Column selection with `col()`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4377b17-dea3-4179-aaa7-a570a96db15e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5723337425000115,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Prob_05",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
