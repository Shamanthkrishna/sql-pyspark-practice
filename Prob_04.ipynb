{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "124c9f92-7f5f-4d8f-a5d8-2b15c4618d04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Most Visited Floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "938c2111-c1b7-4460-949b-4ed6e6cfa5db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Switch to my Catalog\n",
    "USE CATALOG workspace;\n",
    "\n",
    "-- Create schema if not exists\n",
    "CREATE SCHEMA IF NOT EXISTS sql_pyspark_practice;\n",
    "\n",
    "-- Use this schema\n",
    "USE sql_pyspark_practice;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79d56fd0-9bf9-4c8e-a973-062599aacc2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create or replace table entries ( \n",
    "name varchar(20),\n",
    "address varchar(20),\n",
    "email varchar(20),\n",
    "floor int,\n",
    "resources varchar(10));\n",
    "\n",
    "insert into entries \n",
    "values ('A','Bangalore','A@gmail.com',1,'CPU'),('A','Bangalore','A1@gmail.com',1,'CPU'),('A','Bangalore','A2@gmail.com',2,'DESKTOP')\n",
    ",('B','Bangalore','B@gmail.com',2,'DESKTOP'),('B','Bangalore','B1@gmail.com',2,'DESKTOP'),('B','Bangalore','B2@gmail.com',1,'MONITOR');\n",
    "\n",
    "select * from entries;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47e2a8e6-6198-483f-bbc5-327f5c9ac5f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üß© 1Ô∏è‚É£ Understanding the Problem\n",
    "\n",
    "You have a table called **`entries`** with columns something like this:\n",
    "| name | floor | resources | (other cols...) |\n",
    "|------|--------|------------|\n",
    "| John | 2 | Printer |\n",
    "| John | 3 | Scanner |\n",
    "| John | 2 | Projector |\n",
    "| Mary | 1 | Laptop |\n",
    "| Mary | 1 | Printer |\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Your Goal\n",
    "\n",
    "For each **person (`name`)**, you want to find:\n",
    "\n",
    "1. The **most visited floor** (the floor they went to most often)\n",
    "2. The **total number of visits** they made overall\n",
    "3. A list of all **distinct resources** they used\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Real-World Meaning\n",
    "\n",
    "Think of it like analyzing office entry logs:\n",
    "\n",
    "* ‚ÄúWhich floor does each employee visit most?‚Äù\n",
    "* ‚ÄúHow many total visits did they make?‚Äù\n",
    "* ‚ÄúWhat all resources did they use across their visits?‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## üß† 2Ô∏è‚É£ SQL Approach ‚Äî Step by Step\n",
    "\n",
    "Let‚Äôs start with your SQL and explain each part clearly.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1Ô∏è‚É£ ‚Äî Count floor visits per person\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  name, \n",
    "  floor, \n",
    "  COUNT(1) AS floor_visits\n",
    "FROM entries\n",
    "GROUP BY name, floor;\n",
    "```\n",
    "\n",
    "üëâ This gives you how many times each person visited each floor.\n",
    "\n",
    "| name | floor | floor_visits |\n",
    "| ---- | ----- | ------------ |\n",
    "| John | 2     | 2            |\n",
    "| John | 3     | 1            |\n",
    "| Mary | 1     | 2            |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2Ô∏è‚É£ ‚Äî Rank floors per person\n",
    "\n",
    "We want to know which floor was visited the most by each person.\n",
    "\n",
    "```sql\n",
    "RANK() OVER (PARTITION BY name ORDER BY COUNT(1) DESC) AS rn\n",
    "```\n",
    "\n",
    "* `PARTITION BY name`: reset ranking per person\n",
    "* `ORDER BY COUNT(1) DESC`: highest count = rank 1\n",
    "\n",
    "This gives us:\n",
    "\n",
    "| name | floor | floor_visits | rn |\n",
    "| ---- | ----- | ------------ | -- |\n",
    "| John | 2     | 2            | 1  |\n",
    "| John | 3     | 1            | 2  |\n",
    "| Mary | 1     | 2            | 1  |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3Ô∏è‚É£ ‚Äî Calculate total visits and resources\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  name, \n",
    "  COUNT(1) AS total_visits, \n",
    "  STRING_AGG(DISTINCT resources, ',') AS resources_used\n",
    "FROM entries\n",
    "GROUP BY name;\n",
    "```\n",
    "\n",
    "üëâ This gives overall visits and the distinct list of resources per person.\n",
    "\n",
    "| name | total_visits | resources_used            |\n",
    "| ---- | ------------ | ------------------------- |\n",
    "| John | 3            | Printer,Scanner,Projector |\n",
    "| Mary | 2            | Laptop,Printer            |\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4Ô∏è‚É£ ‚Äî Combine both (CTEs + JOIN)\n",
    "\n",
    "You combine the two CTEs:\n",
    "\n",
    "* `floor_visit` gives the **most visited floor**\n",
    "* `total_visits` gives the **summary per person**\n",
    "\n",
    "Then join on `name` and keep only rank = 1:\n",
    "\n",
    "```sql\n",
    "SELECT fv.name, fv.floor AS most_visited_floor, tv.total_visits, tv.resources_used\n",
    "FROM floor_visit fv\n",
    "JOIN total_visits tv ON fv.name = tv.name\n",
    "WHERE fv.rn = 1;\n",
    "```\n",
    "\n",
    "‚úÖ Final Output:\n",
    "\n",
    "| name | most_visited_floor | total_visits | resources_used            |\n",
    "| ---- | ------------------ | ------------ | ------------------------- |\n",
    "| John | 2                  | 3            | Printer,Scanner,Projector |\n",
    "| Mary | 1                  | 2            | Laptop,Printer            |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è 3Ô∏è‚É£ PySpark Approach ‚Äî Step by Step\n",
    "\n",
    "Now, the same logic ‚Äî but using **PySpark transformations**.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1Ô∏è‚É£ ‚Äî Count floor visits per person\n",
    "\n",
    "SQL ‚Üí `GROUP BY name, floor`\n",
    "\n",
    "PySpark:\n",
    "\n",
    "```python\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "floor_counts = (\n",
    "    df.groupBy(\"name\", \"floor\")\n",
    "      .agg(F.count(\"*\").alias(\"floor_visits\"))\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2Ô∏è‚É£ ‚Äî Rank floors using window\n",
    "\n",
    "SQL ‚Üí `RANK() OVER (PARTITION BY name ORDER BY count DESC)`\n",
    "\n",
    "PySpark:\n",
    "\n",
    "```python\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window_rank = Window.partitionBy(\"name\").orderBy(F.desc(\"floor_visits\"))\n",
    "\n",
    "floor_visit = floor_counts.withColumn(\"rn\", F.rank().over(window_rank))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3Ô∏è‚É£ ‚Äî Compute total visits and distinct resources\n",
    "\n",
    "SQL ‚Üí `GROUP BY name` + `STRING_AGG(DISTINCT resources, ',')`\n",
    "\n",
    "PySpark:\n",
    "\n",
    "```python\n",
    "total_visits = (\n",
    "    df.groupBy(\"name\")\n",
    "      .agg(\n",
    "          F.count(\"*\").alias(\"total_visits\"),\n",
    "          F.concat_ws(\",\", F.collect_set(\"resources\")).alias(\"resources_used\")\n",
    "      )\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4Ô∏è‚É£ ‚Äî Join both results & filter rank = 1\n",
    "\n",
    "SQL ‚Üí `JOIN` + `WHERE rn = 1`\n",
    "\n",
    "PySpark:\n",
    "\n",
    "```python\n",
    "result = (\n",
    "    floor_visit.join(total_visits, on=\"name\", how=\"inner\")\n",
    "               .filter(F.col(\"rn\") == 1)\n",
    "               .select(\n",
    "                   \"name\",\n",
    "                   F.col(\"floor\").alias(\"most_visited_floor\"),\n",
    "                   \"total_visits\",\n",
    "                   \"resources_used\"\n",
    "               )\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Final Output (Same as SQL)\n",
    "\n",
    "| name | most_visited_floor | total_visits | resources_used            |\n",
    "| ---- | ------------------ | ------------ | ------------------------- |\n",
    "| John | 2                  | 3            | Printer,Scanner,Projector |\n",
    "| Mary | 1                  | 2            | Laptop,Printer            |\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ 4Ô∏è‚É£ Summary of Approach\n",
    "\n",
    "| Step | What It Does                            | SQL Keyword                    | PySpark Equivalent                            |\n",
    "| ---- | --------------------------------------- | ------------------------------ | --------------------------------------------- |\n",
    "| 1Ô∏è‚É£  | Count floor visits                      | `GROUP BY name, floor`         | `groupBy().agg(F.count())`                    |\n",
    "| 2Ô∏è‚É£  | Rank by visits per name                 | `RANK() OVER(...)`             | `Window.partitionBy().orderBy()` + `F.rank()` |\n",
    "| 3Ô∏è‚É£  | Count total visits + distinct resources | `GROUP BY name` + `STRING_AGG` | `groupBy()` + `concat_ws(collect_set())`      |\n",
    "| 4Ô∏è‚É£  | Combine & filter                        | `JOIN + WHERE rn = 1`          | `.join()` + `.filter(F.col(\"rn\") == 1)`       |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö° Pro Tips:\n",
    "\n",
    "* ‚úÖ Always test intermediate results (`display()` each DataFrame).\n",
    "* ‚úÖ Use `rank()` ‚Üí includes ties; use `dense_rank()` if you want no gaps.\n",
    "* ‚úÖ Prefer `collect_set()` for unique resource names.\n",
    "* ‚úÖ In PySpark, each SQL ‚ÄúCTE‚Äù becomes a DataFrame variable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d51d9f73-72ec-4a00-bf6c-8d4e2487a9ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Steps\n",
    "- Count the floor visits by grouping it by Name and floor and counting all the rows in each group\n",
    "- Upon counting it we can rank it based on the count \n",
    "- This will give us the floor visit counts\n",
    "- Then total visits is calculted\n",
    "- Group by name and count all the rows this gives the total visits\n",
    "- String agg gives the aggregation of all rows based on the group,m distinct filters out the duplicate values\n",
    "- Converting all these queires into ctes and querying a single query usign these ctes will give the required output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86a76c2f-aa0e-412f-8845-560c7eabc1c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Assuming 'entries' is your source table\n",
    "df = spark.table(\"entries\")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1Ô∏è‚É£ Floor visit counts + rank\n",
    "# -------------------------------\n",
    "window_rank = Window.partitionBy(\"name\").orderBy(F.desc(\"floor_visits\"))\n",
    "\n",
    "floor_visit = (\n",
    "    df.groupBy(\"name\", \"floor\")\n",
    "      .agg(F.count(\"*\").alias(\"floor_visits\"))\n",
    "      .withColumn(\"rn\", F.rank().over(window_rank))\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2Ô∏è‚É£ Total visits + distinct resources\n",
    "# -------------------------------\n",
    "total_visits = (\n",
    "    df.groupBy(\"name\")\n",
    "      .agg(\n",
    "          F.count(\"*\").alias(\"total_visits\"),\n",
    "          F.concat_ws(\",\", F.collect_set(\"resources\")).alias(\"resources_used\")\n",
    "      )\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3Ô∏è‚É£ Join and filter for most visited floor\n",
    "# -------------------------------\n",
    "result = (\n",
    "    floor_visit.join(total_visits, on=\"name\", how=\"inner\")\n",
    "               .filter(F.col(\"rn\") == 1)\n",
    "               .select(\n",
    "                   \"name\",\n",
    "                   F.col(\"floor\").alias(\"most_visited_floor\"),\n",
    "                   \"total_visits\",\n",
    "                   \"resources_used\"\n",
    "               )\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4Ô∏è‚É£ Show or display the final result\n",
    "# -------------------------------\n",
    "display(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c9399b-5adb-4dfb-b889-2857f9b9fcc3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762966003093}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with floor_visit as (\n",
    "  select name, floor, count(1),\n",
    "  rank() over(partition by name order by count(1) desc) as rn\n",
    "  from entries\n",
    "  group by name, floor\n",
    "),total_visits as (\n",
    "  select name, count(1) as total_visits, string_agg(distinct resources, ',') as resources_used\n",
    "  from entries\n",
    "  group by name\n",
    ")\n",
    "\n",
    "select fv.name, fv.floor as most_visited_floor, tv.total_visits, tv.resources_used\n",
    "from floor_visit fv\n",
    "inner join total_visits tv on fv.name = tv.name\n",
    "where rn = 1;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b0210c7-40f3-4590-9ec1-1746ef38301e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "512c06fb-3315-40e2-9739-b71d7c75c4be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Prob_04",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
