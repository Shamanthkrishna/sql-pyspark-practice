{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0b72117-9e67-4e29-8378-0ca53bb3c936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Amazon Interview Question\n",
    "Write a query to provide the date for nth occurence of Sunday in future from given date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bf4e1d4-137b-44da-b760-534bef8c0223",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "WITH params AS (\n",
    "  SELECT DATE('2022-01-01') AS start_date, 3 AS n\n",
    "),\n",
    "calc AS (\n",
    "  SELECT \n",
    "    start_date,\n",
    "    n,\n",
    "    DAYOFWEEK(start_date) AS weekday_num\n",
    "  FROM params\n",
    "),\n",
    "next_sunday AS (\n",
    "  SELECT\n",
    "    start_date,\n",
    "    n,\n",
    "    CASE \n",
    "      WHEN DAYOFWEEK(start_date) = 1 THEN 0  -- Already Sunday\n",
    "      ELSE 8 - DAYOFWEEK(start_date)\n",
    "    END AS days_to_next_sunday\n",
    "  FROM calc\n",
    ")\n",
    "SELECT \n",
    "  start_date,\n",
    "  n,\n",
    "  DATE_ADD(start_date, days_to_next_sunday + ((n - 1) * 7)) AS nth_sunday_date\n",
    "FROM next_sunday;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc2b4b67-20f2-4ff9-b9c1-6eac550f39ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Create Spark session (already available in Databricks)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Input parameters\n",
    "start_date = '2022-01-01'\n",
    "n = 3\n",
    "\n",
    "# Create initial DataFrame with params\n",
    "df = spark.createDataFrame([(start_date, n)], [\"start_date\", \"n\"]) \\\n",
    "           .withColumn(\"start_date\", F.to_date(\"start_date\"))\n",
    "\n",
    "# Step 1️⃣: Calculate weekday number (Sunday = 1, Saturday = 7)\n",
    "df = df.withColumn(\"weekday_num\", F.dayofweek(\"start_date\"))\n",
    "\n",
    "# Step 2️⃣: Calculate days to next Sunday\n",
    "df = df.withColumn(\n",
    "    \"days_to_next_sunday\",\n",
    "    F.when(F.col(\"weekday_num\") == 1, F.lit(0))  # Already Sunday\n",
    "     .otherwise(8 - F.col(\"weekday_num\"))         # Days until next Sunday\n",
    ")\n",
    "\n",
    "# Step 3️⃣: Add (n-1)*7 + days_to_next_sunday\n",
    "df = df.withColumn(\n",
    "    \"nth_sunday_date\",\n",
    "    F.date_add(\n",
    "        \"start_date\",\n",
    "        F.col(\"days_to_next_sunday\") + ((F.col(\"n\") - 1) * 7).cast(\"int\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 4️⃣: Display final result\n",
    "display(df.select(\"start_date\", \"n\", \"nth_sunday_date\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Prob_06",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
